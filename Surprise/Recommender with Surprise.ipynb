{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load up the libraries\n",
    "import pandas as pd\n",
    "from surprise import SVD\n",
    "from surprise import KNNBaseline\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import LeaveOneOut\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.9467849999896248\n",
      "MAE:  0.7464520353995886\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/lianj/Desktop/Udemy/ml-100k/movies.txt', header = None, sep = '\\t')\n",
    "df.columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
    "trainSet, testSet = train_test_split(data, test_size=.25, random_state=0)\n",
    "algo = SVD(random_state=0)\n",
    "algo.fit(trainSet)\n",
    "predictions = algo.test(testSet)\n",
    "\n",
    "def MAE(predictions):\n",
    "        return accuracy.mae(predictions, verbose=False)\n",
    "def RMSE(predictions):\n",
    "        return accuracy.rmse(predictions, verbose=False)\n",
    "    \n",
    "print(\"RMSE: \", RMSE(predictions))\n",
    "print(\"MAE: \", MAE(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9370  0.9333  0.9374  0.9382  0.9418  0.9375  0.0027  \n",
      "MAE (testset)     0.7380  0.7384  0.7383  0.7435  0.7401  0.7397  0.0021  \n",
      "Fit time          3.88    4.38    4.35    5.35    4.21    4.43    0.49    \n",
      "Test time         0.18    0.12    0.11    0.11    0.14    0.13    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.93696997, 0.93331873, 0.93744167, 0.93819548, 0.94175364]),\n",
       " 'test_mae': array([0.73802902, 0.73837263, 0.7383334 , 0.74352991, 0.74005939]),\n",
       " 'fit_time': (3.8781239986419678,\n",
       "  4.382630109786987,\n",
       "  4.348900079727173,\n",
       "  5.347845077514648,\n",
       "  4.209790468215942),\n",
       " 'test_time': (0.17554354667663574,\n",
       "  0.11870956420898438,\n",
       "  0.10933446884155273,\n",
       "  0.10870909690856934,\n",
       "  0.13962674140930176)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTopN(predictions, n=10, minimumRating=4.0):\n",
    "    '''\n",
    "    input = predictions\n",
    "    output = top N predictions for a user and stored in a defalut dictionary\n",
    "    '''\n",
    "    topN = defaultdict(list)\n",
    "    for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
    "        if (estimatedRating >= minimumRating):\n",
    "            topN[int(userID)].append((int(movieID), estimatedRating))\n",
    "\n",
    "    for userID, ratings in topN.items():\n",
    "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        topN[int(userID)] = ratings[:n]\n",
    "\n",
    "    return topN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
    "\n",
    "for trainSet, testSet in LOOCV.split(data):\n",
    "    # Train model without left-out ratings\n",
    "    algo.fit(trainSet)\n",
    "    # Predicts ratings for left-out ratings only\n",
    "    leftOutPredictions = algo.test(testSet)\n",
    "    # Build predictions for all ratings not in the training set\n",
    "    bigTestSet = trainSet.build_anti_testset()\n",
    "    allPredictions = algo.test(bigTestSet)\n",
    "    # Compute top 10 recs for each user\n",
    "    topNPredicted = GetTopN(allPredictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(64, 4.516063507687135),\n",
       " (114, 4.509139907231062),\n",
       " (318, 4.492523960075983),\n",
       " (515, 4.437435258698688),\n",
       " (408, 4.4309402453055196),\n",
       " (480, 4.412107354531763),\n",
       " (50, 4.410538949398632),\n",
       " (169, 4.364397262145547),\n",
       " (483, 4.352133872803232),\n",
       " (513, 4.33617690355655)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 predictions for userId 196\n",
    "topNPredicted[196]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hit Rate\n",
    "\n",
    "- We will use hit rate to evaluate how good our top N ratings\n",
    "\n",
    "- The process of compute hit rate for a single user:\n",
    "   - Find all items in this user’s history in the training data.\n",
    "   - Intentionally remove one of these items ( Leave-One-Out cross-validation).\n",
    "   - Use all other items to feed the recommender and ask for top 10 recommendations.\n",
    "   - If the removed item appear in the top 10 recommendations, it is a hit. If not, it’s not a hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hit Rate:  0.03711558854718982\n"
     ]
    }
   ],
   "source": [
    "# See how often we recommended a movie the user actually rated\n",
    "def HitRate(topNPredicted, leftOutPredictions):\n",
    "    hits = 0\n",
    "    total = 0\n",
    "\n",
    " # For each left-out rating\n",
    "    for leftOut in leftOutPredictions:\n",
    "        userID = leftOut[0]\n",
    "        leftOutMovieID = leftOut[1]\n",
    "        # Is it in the predicted top 10 for this user?\n",
    "        hit = False\n",
    "        for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "            if (int(leftOutMovieID) == int(movieID)):\n",
    "                hit = True\n",
    "                break\n",
    "        if (hit) :\n",
    "            hits += 1\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    # Compute overall precision\n",
    "    return hits/total\n",
    "print(\"\\nHit Rate: \", HitRate(topNPredicted, leftOutPredictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole hit rate of the system is the count of hits, divided by the test user count. It measures how often we are able to recommend a removed rating, higher is better.\n",
    "\n",
    "## Hits By Ratings\n",
    "\n",
    "- Breaking down hit rates by ratings to see which rating category is better predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate by Rating value: \n",
      "2.0 0.009174311926605505\n",
      "3.0 0.017699115044247787\n",
      "4.0 0.025477707006369428\n",
      "5.0 0.09734513274336283\n"
     ]
    }
   ],
   "source": [
    "def RatingHitRate(topNPredicted, leftOutPredictions):\n",
    "    hits = defaultdict(float)\n",
    "    total = defaultdict(float)\n",
    "    # For each left-out rating\n",
    "    for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "        # Is it in the predicted top N for this user?\n",
    "        hit = False\n",
    "        for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "            if (int(leftOutMovieID) == movieID):\n",
    "                hit = True\n",
    "                break\n",
    "        if (hit) :\n",
    "            hits[actualRating] += 1\n",
    "        total[actualRating] += 1\n",
    "\n",
    "    # Compute overall precision\n",
    "    for rating in sorted(hits.keys()):\n",
    "        print(rating, hits[rating] / total[rating])\n",
    "print(\"Hit Rate by Rating value: \")\n",
    "RatingHitRate(topNPredicted, leftOutPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Hit Rates\n",
    "\n",
    "- In this case we can only look at hit rates in a defined range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Hit Rate (rating >= 3.5):  0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "def CumulativeHitRate(topNPredicted, leftOutPredictions, ratingCutoff=0):\n",
    "    hits = 0\n",
    "    total = 0\n",
    "    # For each left-out rating\n",
    "    for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "        # Only look at ability to recommend things the users actually liked...\n",
    "        if (actualRating >= ratingCutoff):\n",
    "            # Is it in the predicted top 10 for this user?\n",
    "            hit = False\n",
    "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "                if (int(leftOutMovieID) == movieID):\n",
    "                    hit = True\n",
    "                    break\n",
    "            if (hit) :\n",
    "                hits += 1\n",
    "            total += 1\n",
    "\n",
    "        # Compute overall precision\n",
    "    return hits/total\n",
    "print(\"Cumulative Hit Rate (rating >= 3.5): \", CumulativeHitRate(topNPredicted, leftOutPredictions, 3.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Reciprocal Hit Ranking (ARHR)\n",
    "\n",
    "- Commonly used metric for ranking evaluation of Top-N recommender systems, that only takes into account where the first relevant result occurs. We get more credit for recommending an item in which user rated on the top of the rank than on the bottom of the rank. Higher is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reciprocal Hit Rank:  0.013899829992088738\n"
     ]
    }
   ],
   "source": [
    "# Compute ARHR\n",
    "def AverageReciprocalHitRank(topNPredicted, leftOutPredictions):\n",
    "    summation = 0\n",
    "    total = 0\n",
    "    # For each left-out rating\n",
    "    for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "        # Is it in the predicted top N for this user?\n",
    "        hitRank = 0\n",
    "        rank = 0\n",
    "        for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "            rank = rank + 1\n",
    "            if (int(leftOutMovieID) == movieID):\n",
    "                hitRank = rank\n",
    "                break\n",
    "        if (hitRank > 0) :\n",
    "                summation += 1.0 / hitRank\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    return summation / total\n",
    "\n",
    "print(\"Average Reciprocal Hit Rank: \", AverageReciprocalHitRank(topNPredicted, leftOutPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
